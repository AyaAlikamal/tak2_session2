{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed963b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db833af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Thu Sep 29 13:21:50 2022', '__version__': '1.0', '__globals__': [], 'features': array([[ 0.,  0.,  4., ..., 11.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  4., 16., ...,  7.,  4.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  3., ..., 14.,  7.,  0.],\n",
      "       [ 0.,  0.,  2., ..., 13.,  7.,  0.],\n",
      "       [ 0.,  0., 10., ..., 16., 16., 10.]]), 'label': array([[1., 4., 2., ..., 6., 6., 1.]])}\n",
      "dict_items([('__header__', b'MATLAB 5.0 MAT-file Platform: posix, Created on: Thu Sep 29 13:21:50 2022'), ('__version__', '1.0'), ('__globals__', []), ('features', array([[ 0.,  0.,  4., ..., 11.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  4., 16., ...,  7.,  4.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  3., ..., 14.,  7.,  0.],\n",
      "       [ 0.,  0.,  2., ..., 13.,  7.,  0.],\n",
      "       [ 0.,  0., 10., ..., 16., 16., 10.]])), ('label', array([[1., 4., 2., ..., 6., 6., 1.]]))])\n",
      "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Thu Sep 29 13:21:50 2022', '__version__': '1.0', '__globals__': [], 'features': array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  7., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  4., ...,  0.,  0.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  7., ..., 11.,  1.,  0.],\n",
      "       [ 0.,  0.,  1., ..., 14.,  7.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  5.,  0.,  0.]]), 'label': array([[4., 7., 7., 8., 7., 4., 4., 7., 6., 5., 3., 9., 5., 4., 1., 0.,\n",
      "        7., 3., 4., 4., 9., 2., 7., 8., 7., 6., 1., 0., 8., 0., 1., 7.,\n",
      "        5., 3., 2., 9., 8., 1., 2., 1., 8., 4., 6., 4., 6., 8., 2., 5.,\n",
      "        0., 9., 9., 9., 5., 3., 3., 4., 4., 9., 6., 2., 1., 9., 5., 9.,\n",
      "        9., 6., 3., 8., 0., 5., 9., 0., 0., 1., 0., 5., 1., 6., 6., 8.,\n",
      "        2., 9., 2., 9., 4., 7., 6., 0., 2., 6., 2., 6., 5., 1., 8., 1.,\n",
      "        4., 7., 2., 0., 6., 8., 6., 5., 4., 5., 8., 2., 5., 7., 4., 8.,\n",
      "        6., 7., 5., 0., 1., 3., 9., 9., 3., 4., 8., 2., 8., 5., 1., 3.,\n",
      "        9., 7., 2., 3., 0., 2., 6., 7., 2., 8., 8., 2., 5., 1., 7., 5.,\n",
      "        1., 1., 5., 0., 8., 1., 1., 8., 0., 0., 5., 8., 0., 2., 2., 2.,\n",
      "        3., 1., 9., 1., 7., 6., 0., 1., 6., 3., 1., 5., 8., 1., 4., 9.,\n",
      "        9., 3., 3., 2., 8., 8., 7., 7., 5., 5., 8., 7., 8., 7., 7., 8.,\n",
      "        1., 6., 8., 8., 6., 9., 2., 0., 3., 3., 1., 0., 8., 5., 4., 5.,\n",
      "        3., 7., 4., 2., 2., 0., 0., 6., 8., 0., 2., 8., 2., 5., 8., 9.,\n",
      "        4., 7., 5., 1., 6., 3., 4., 0., 8., 6., 9., 1., 6., 8., 6., 9.,\n",
      "        6., 7., 4., 4., 8., 8., 3., 1., 8., 4., 6., 7., 0., 7., 9., 4.,\n",
      "        1., 8., 4., 8., 1., 0., 8., 1., 8., 6., 0., 1., 7., 4., 0., 5.,\n",
      "        1., 3., 6., 8., 0., 4., 8., 4., 5., 0., 9., 9., 3., 7., 8., 0.,\n",
      "        3., 2., 1., 3., 1., 4., 3., 9., 9., 1., 0., 5., 7., 8., 7., 8.,\n",
      "        7., 5., 7., 5., 0., 7., 3., 3., 5., 8., 9., 1., 9., 9., 2., 6.,\n",
      "        2., 9., 7., 7., 9., 2., 8., 5., 3., 6., 8., 2., 4., 3., 7., 9.,\n",
      "        8., 4., 0., 0., 0., 9., 9., 4., 3., 2., 4., 6., 6., 3., 7., 8.,\n",
      "        6., 3., 7., 1., 7., 5., 6., 4.]])}\n",
      "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Thu Sep 29 13:21:50 2022', '__version__': '1.0', '__globals__': [], 'features': array([[ 0.,  0., 10., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  3.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 11.,  1.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  1., ...,  4.,  0.,  0.],\n",
      "       [ 0.,  0.,  4., ...,  9.,  0.,  0.],\n",
      "       [ 0.,  0.,  8., ...,  7.,  0.,  0.]]), 'label': array([[4., 1., 6., 0., 7., 5., 5., 2., 2., 7., 1., 8., 6., 0., 9., 1.,\n",
      "        8., 8., 6., 4., 1., 5., 1., 7., 6., 6., 0., 7., 9., 9., 9., 7.,\n",
      "        3., 3., 1., 2., 4., 1., 3., 3., 1., 4., 8., 9., 2., 0., 9., 7.,\n",
      "        9., 2., 8., 2., 5., 4., 8., 7., 1., 0., 5., 7., 9., 6., 8., 9.,\n",
      "        5., 0., 4., 2., 6., 0., 7., 6., 5., 6., 1., 5., 7., 4., 2., 5.,\n",
      "        0., 0., 0., 1., 7., 0., 1., 5., 9., 2., 6., 5., 2., 2., 6., 3.,\n",
      "        0., 3., 2., 7., 8., 6., 8., 0., 4., 9., 8., 6., 9., 3., 4., 5.,\n",
      "        9., 2., 8., 9., 9., 7., 3., 1., 9., 4., 0., 3., 1., 0., 3., 6.,\n",
      "        6., 6., 4., 8., 3., 3., 5., 3., 3., 7., 5., 5., 5., 5., 0., 7.,\n",
      "        4., 6., 5., 6., 0., 1., 3., 3., 7., 8., 7., 6., 5., 9., 4., 4.,\n",
      "        1., 0., 6., 8., 6., 3., 5., 7., 3., 5., 4., 3., 4., 3., 3., 2.,\n",
      "        6., 1., 7., 1., 0., 4., 2., 1., 1., 2., 0., 5., 8., 3., 8., 9.,\n",
      "        1., 0., 9., 3., 2., 8., 8., 5., 5., 7., 4., 2., 7., 4., 6., 3.,\n",
      "        5., 7., 8., 5., 1., 4., 8., 3., 4., 5., 4., 7., 5., 9., 9., 7.,\n",
      "        4., 2., 7., 4., 5., 1., 3., 1., 1., 2., 5., 6., 1., 7., 1., 2.,\n",
      "        8., 9., 0., 4., 0., 8., 0., 5., 4., 1., 1., 5., 2., 3., 8., 5.,\n",
      "        2., 4., 6., 8., 9., 4., 9., 4., 4., 8., 0., 8., 9., 8., 8., 6.,\n",
      "        1., 9., 0., 7., 8., 0., 8., 5., 8., 3., 3., 5., 0., 6., 1., 5.,\n",
      "        4., 4., 3., 6., 5., 7., 6., 3., 3., 6., 6., 4., 5., 9., 4., 4.,\n",
      "        7., 8., 1., 7., 7., 0., 0., 8., 7., 5., 4., 1., 7., 6., 2., 2.,\n",
      "        5., 2., 8., 2., 5., 5., 3., 8., 9., 1., 7., 8., 5., 8., 4., 1.,\n",
      "        8., 1., 6., 9., 1., 4., 7., 3., 3., 3., 1., 0., 7., 2., 6., 0.,\n",
      "        7., 3., 8., 4., 5., 3., 2., 9.]])}\n",
      "5\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "train= loadmat(\"train.mat\") # taking the data input using loadmt fn to read it\n",
    "print(train)\n",
    "print(train.items())\n",
    "val = loadmat(\"val.mat\")\n",
    "print(val)\n",
    "test=loadmat(\"test.mat\")\n",
    "print(test)\n",
    "print(train.__len__())\n",
    "print(type(train))\n",
    "print(type(val))\n",
    "print(type(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6e86036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [[ 0.  0.  4. ... 11.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  4. 16. ...  7.  4.  0.]\n",
      " ...\n",
      " [ 0.  0.  3. ... 14.  7.  0.]\n",
      " [ 0.  0.  2. ... 13.  7.  0.]\n",
      " [ 0.  0. 10. ... 16. 16. 10.]] [[1. 4. 2. ... 6. 6. 1.]]\n",
      "(1077, 64)\n",
      "(1077, 1)\n",
      "validation [[ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  7. ...  0.  0.  0.]\n",
      " [ 0.  0.  4. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  7. ... 11.  1.  0.]\n",
      " [ 0.  0.  1. ... 14.  7.  0.]\n",
      " [ 0.  0.  0. ...  5.  0.  0.]] [[4. 7. 7. 8. 7. 4. 4. 7. 6. 5. 3. 9. 5. 4. 1. 0. 7. 3. 4. 4. 9. 2. 7. 8.\n",
      "  7. 6. 1. 0. 8. 0. 1. 7. 5. 3. 2. 9. 8. 1. 2. 1. 8. 4. 6. 4. 6. 8. 2. 5.\n",
      "  0. 9. 9. 9. 5. 3. 3. 4. 4. 9. 6. 2. 1. 9. 5. 9. 9. 6. 3. 8. 0. 5. 9. 0.\n",
      "  0. 1. 0. 5. 1. 6. 6. 8. 2. 9. 2. 9. 4. 7. 6. 0. 2. 6. 2. 6. 5. 1. 8. 1.\n",
      "  4. 7. 2. 0. 6. 8. 6. 5. 4. 5. 8. 2. 5. 7. 4. 8. 6. 7. 5. 0. 1. 3. 9. 9.\n",
      "  3. 4. 8. 2. 8. 5. 1. 3. 9. 7. 2. 3. 0. 2. 6. 7. 2. 8. 8. 2. 5. 1. 7. 5.\n",
      "  1. 1. 5. 0. 8. 1. 1. 8. 0. 0. 5. 8. 0. 2. 2. 2. 3. 1. 9. 1. 7. 6. 0. 1.\n",
      "  6. 3. 1. 5. 8. 1. 4. 9. 9. 3. 3. 2. 8. 8. 7. 7. 5. 5. 8. 7. 8. 7. 7. 8.\n",
      "  1. 6. 8. 8. 6. 9. 2. 0. 3. 3. 1. 0. 8. 5. 4. 5. 3. 7. 4. 2. 2. 0. 0. 6.\n",
      "  8. 0. 2. 8. 2. 5. 8. 9. 4. 7. 5. 1. 6. 3. 4. 0. 8. 6. 9. 1. 6. 8. 6. 9.\n",
      "  6. 7. 4. 4. 8. 8. 3. 1. 8. 4. 6. 7. 0. 7. 9. 4. 1. 8. 4. 8. 1. 0. 8. 1.\n",
      "  8. 6. 0. 1. 7. 4. 0. 5. 1. 3. 6. 8. 0. 4. 8. 4. 5. 0. 9. 9. 3. 7. 8. 0.\n",
      "  3. 2. 1. 3. 1. 4. 3. 9. 9. 1. 0. 5. 7. 8. 7. 8. 7. 5. 7. 5. 0. 7. 3. 3.\n",
      "  5. 8. 9. 1. 9. 9. 2. 6. 2. 9. 7. 7. 9. 2. 8. 5. 3. 6. 8. 2. 4. 3. 7. 9.\n",
      "  8. 4. 0. 0. 0. 9. 9. 4. 3. 2. 4. 6. 6. 3. 7. 8. 6. 3. 7. 1. 7. 5. 6. 4.]]\n",
      "(360, 64)\n",
      "(360, 1)\n",
      "test [[ 0.  0. 10. ...  0.  0.  0.]\n",
      " [ 0.  0.  1. ...  3.  0.  0.]\n",
      " [ 0.  0.  0. ... 11.  1.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  4.  0.  0.]\n",
      " [ 0.  0.  4. ...  9.  0.  0.]\n",
      " [ 0.  0.  8. ...  7.  0.  0.]] [[4. 1. 6. 0. 7. 5. 5. 2. 2. 7. 1. 8. 6. 0. 9. 1. 8. 8. 6. 4. 1. 5. 1. 7.\n",
      "  6. 6. 0. 7. 9. 9. 9. 7. 3. 3. 1. 2. 4. 1. 3. 3. 1. 4. 8. 9. 2. 0. 9. 7.\n",
      "  9. 2. 8. 2. 5. 4. 8. 7. 1. 0. 5. 7. 9. 6. 8. 9. 5. 0. 4. 2. 6. 0. 7. 6.\n",
      "  5. 6. 1. 5. 7. 4. 2. 5. 0. 0. 0. 1. 7. 0. 1. 5. 9. 2. 6. 5. 2. 2. 6. 3.\n",
      "  0. 3. 2. 7. 8. 6. 8. 0. 4. 9. 8. 6. 9. 3. 4. 5. 9. 2. 8. 9. 9. 7. 3. 1.\n",
      "  9. 4. 0. 3. 1. 0. 3. 6. 6. 6. 4. 8. 3. 3. 5. 3. 3. 7. 5. 5. 5. 5. 0. 7.\n",
      "  4. 6. 5. 6. 0. 1. 3. 3. 7. 8. 7. 6. 5. 9. 4. 4. 1. 0. 6. 8. 6. 3. 5. 7.\n",
      "  3. 5. 4. 3. 4. 3. 3. 2. 6. 1. 7. 1. 0. 4. 2. 1. 1. 2. 0. 5. 8. 3. 8. 9.\n",
      "  1. 0. 9. 3. 2. 8. 8. 5. 5. 7. 4. 2. 7. 4. 6. 3. 5. 7. 8. 5. 1. 4. 8. 3.\n",
      "  4. 5. 4. 7. 5. 9. 9. 7. 4. 2. 7. 4. 5. 1. 3. 1. 1. 2. 5. 6. 1. 7. 1. 2.\n",
      "  8. 9. 0. 4. 0. 8. 0. 5. 4. 1. 1. 5. 2. 3. 8. 5. 2. 4. 6. 8. 9. 4. 9. 4.\n",
      "  4. 8. 0. 8. 9. 8. 8. 6. 1. 9. 0. 7. 8. 0. 8. 5. 8. 3. 3. 5. 0. 6. 1. 5.\n",
      "  4. 4. 3. 6. 5. 7. 6. 3. 3. 6. 6. 4. 5. 9. 4. 4. 7. 8. 1. 7. 7. 0. 0. 8.\n",
      "  7. 5. 4. 1. 7. 6. 2. 2. 5. 2. 8. 2. 5. 5. 3. 8. 9. 1. 7. 8. 5. 8. 4. 1.\n",
      "  8. 1. 6. 9. 1. 4. 7. 3. 3. 3. 1. 0. 7. 2. 6. 0. 7. 3. 8. 4. 5. 3. 2. 9.]]\n",
      "(360, 64)\n",
      "(360, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train= train['features'] # taking the colum called feature as a x_train \n",
    "Y_train= train['label']     # taking the last colum as label called y_train\n",
    "print(\"train\",X_train,Y_train)\n",
    "print(X_train.shape)\n",
    "Y_train=np.reshape(Y_train,(1077,1)) #reshape the y_train to allow the fitting process \n",
    "print(Y_train.shape)\n",
    "X_val= val['features']  # taking the colum called feature as a x_val \n",
    "Y_val= val['label']    # taking the last colum as  label calledy_val\n",
    "print(\"validation\",X_val,Y_val)\n",
    "print(X_val.shape)\n",
    "Y_val=np.reshape(Y_val,(360,1)) #reshape the y_val to allow the fitting process \n",
    "print(Y_val.shape) \n",
    "X_test= test['features']  # taking the colum called feature as a x_test\n",
    "Y_test= test['label']     # taking the last colum as  label calledy_test\n",
    "print(\"test\",X_test,Y_test)\n",
    "print(X_test.shape)\n",
    "Y_test=np.reshape(Y_test,(360,1)) #reshape the y_test to allow the fitting process \n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832da03c",
   "metadata": {},
   "source": [
    "# Decision tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b703d65",
   "metadata": {},
   "source": [
    "Decision Tree made output lower than 95% whatever the depth was may be because it is not the right model to work with \n",
    "This value of hyperprameters has been chosen because it achieve high accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "763f3658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "classification = tree.DecisionTreeClassifier(max_depth=17,random_state=43)#selecting the decision tree depth (hyperparameter)which help increase the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "568b09f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = classification.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3f75802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted labels is \n",
      " [4. 7. 7. 8. 4. 7. 4. 7. 6. 5. 3. 9. 5. 4. 1. 0. 7. 3. 4. 2. 9. 2. 7. 3.\n",
      " 7. 6. 1. 0. 8. 0. 9. 7. 5. 2. 2. 9. 0. 1. 2. 1. 8. 4. 6. 4. 6. 8. 2. 5.\n",
      " 0. 3. 8. 9. 5. 3. 3. 8. 4. 9. 6. 2. 1. 9. 5. 9. 9. 6. 3. 8. 4. 5. 0. 0.\n",
      " 0. 4. 0. 5. 1. 5. 6. 2. 2. 9. 2. 9. 4. 7. 6. 0. 2. 6. 2. 6. 2. 1. 7. 2.\n",
      " 7. 7. 2. 0. 6. 8. 6. 5. 0. 5. 8. 2. 5. 7. 4. 8. 6. 7. 5. 0. 4. 3. 9. 9.\n",
      " 3. 4. 8. 2. 8. 5. 6. 3. 9. 7. 2. 3. 4. 2. 6. 7. 2. 4. 8. 2. 7. 2. 7. 5.\n",
      " 4. 4. 8. 0. 8. 1. 1. 8. 0. 0. 9. 8. 0. 2. 2. 2. 3. 1. 9. 1. 9. 6. 0. 2.\n",
      " 6. 3. 8. 5. 8. 1. 4. 9. 9. 3. 3. 2. 3. 2. 7. 7. 5. 5. 8. 7. 8. 7. 7. 8.\n",
      " 1. 6. 4. 8. 6. 9. 2. 0. 3. 3. 8. 0. 2. 7. 4. 4. 3. 7. 4. 2. 4. 0. 0. 6.\n",
      " 7. 0. 2. 8. 2. 5. 8. 9. 0. 7. 5. 1. 6. 3. 4. 0. 8. 6. 7. 1. 0. 8. 6. 9.\n",
      " 6. 7. 4. 4. 8. 7. 7. 1. 8. 4. 6. 7. 0. 6. 9. 4. 1. 2. 4. 8. 1. 0. 7. 1.\n",
      " 8. 6. 5. 1. 7. 4. 0. 5. 1. 3. 6. 8. 0. 4. 8. 4. 5. 0. 8. 9. 3. 7. 8. 0.\n",
      " 3. 2. 1. 3. 1. 1. 3. 9. 9. 3. 0. 5. 7. 8. 7. 8. 7. 5. 7. 5. 0. 7. 3. 3.\n",
      " 5. 8. 9. 1. 9. 9. 2. 6. 2. 9. 7. 7. 9. 0. 4. 5. 2. 6. 8. 2. 4. 5. 7. 9.\n",
      " 8. 4. 0. 0. 0. 8. 9. 4. 3. 6. 4. 6. 6. 8. 7. 5. 6. 9. 7. 1. 7. 5. 6. 4.]\n",
      "truth table\n",
      " [[4.]\n",
      " [7.]\n",
      " [7.]\n",
      " [8.]\n",
      " [7.]\n",
      " [4.]\n",
      " [4.]\n",
      " [7.]\n",
      " [6.]\n",
      " [5.]\n",
      " [3.]\n",
      " [9.]\n",
      " [5.]\n",
      " [4.]\n",
      " [1.]\n",
      " [0.]\n",
      " [7.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [9.]\n",
      " [2.]\n",
      " [7.]\n",
      " [8.]\n",
      " [7.]\n",
      " [6.]\n",
      " [1.]\n",
      " [0.]\n",
      " [8.]\n",
      " [0.]\n",
      " [1.]\n",
      " [7.]\n",
      " [5.]\n",
      " [3.]\n",
      " [2.]\n",
      " [9.]\n",
      " [8.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [8.]\n",
      " [4.]\n",
      " [6.]\n",
      " [4.]\n",
      " [6.]\n",
      " [8.]\n",
      " [2.]\n",
      " [5.]\n",
      " [0.]\n",
      " [9.]\n",
      " [9.]\n",
      " [9.]\n",
      " [5.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [9.]\n",
      " [6.]\n",
      " [2.]\n",
      " [1.]\n",
      " [9.]\n",
      " [5.]\n",
      " [9.]\n",
      " [9.]\n",
      " [6.]\n",
      " [3.]\n",
      " [8.]\n",
      " [0.]\n",
      " [5.]\n",
      " [9.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [5.]\n",
      " [1.]\n",
      " [6.]\n",
      " [6.]\n",
      " [8.]\n",
      " [2.]\n",
      " [9.]\n",
      " [2.]\n",
      " [9.]\n",
      " [4.]\n",
      " [7.]\n",
      " [6.]\n",
      " [0.]\n",
      " [2.]\n",
      " [6.]\n",
      " [2.]\n",
      " [6.]\n",
      " [5.]\n",
      " [1.]\n",
      " [8.]\n",
      " [1.]\n",
      " [4.]\n",
      " [7.]\n",
      " [2.]\n",
      " [0.]\n",
      " [6.]\n",
      " [8.]\n",
      " [6.]\n",
      " [5.]\n",
      " [4.]\n",
      " [5.]\n",
      " [8.]\n",
      " [2.]\n",
      " [5.]\n",
      " [7.]\n",
      " [4.]\n",
      " [8.]\n",
      " [6.]\n",
      " [7.]\n",
      " [5.]\n",
      " [0.]\n",
      " [1.]\n",
      " [3.]\n",
      " [9.]\n",
      " [9.]\n",
      " [3.]\n",
      " [4.]\n",
      " [8.]\n",
      " [2.]\n",
      " [8.]\n",
      " [5.]\n",
      " [1.]\n",
      " [3.]\n",
      " [9.]\n",
      " [7.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [6.]\n",
      " [7.]\n",
      " [2.]\n",
      " [8.]\n",
      " [8.]\n",
      " [2.]\n",
      " [5.]\n",
      " [1.]\n",
      " [7.]\n",
      " [5.]\n",
      " [1.]\n",
      " [1.]\n",
      " [5.]\n",
      " [0.]\n",
      " [8.]\n",
      " [1.]\n",
      " [1.]\n",
      " [8.]\n",
      " [0.]\n",
      " [0.]\n",
      " [5.]\n",
      " [8.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [9.]\n",
      " [1.]\n",
      " [7.]\n",
      " [6.]\n",
      " [0.]\n",
      " [1.]\n",
      " [6.]\n",
      " [3.]\n",
      " [1.]\n",
      " [5.]\n",
      " [8.]\n",
      " [1.]\n",
      " [4.]\n",
      " [9.]\n",
      " [9.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [8.]\n",
      " [8.]\n",
      " [7.]\n",
      " [7.]\n",
      " [5.]\n",
      " [5.]\n",
      " [8.]\n",
      " [7.]\n",
      " [8.]\n",
      " [7.]\n",
      " [7.]\n",
      " [8.]\n",
      " [1.]\n",
      " [6.]\n",
      " [8.]\n",
      " [8.]\n",
      " [6.]\n",
      " [9.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [8.]\n",
      " [5.]\n",
      " [4.]\n",
      " [5.]\n",
      " [3.]\n",
      " [7.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [6.]\n",
      " [8.]\n",
      " [0.]\n",
      " [2.]\n",
      " [8.]\n",
      " [2.]\n",
      " [5.]\n",
      " [8.]\n",
      " [9.]\n",
      " [4.]\n",
      " [7.]\n",
      " [5.]\n",
      " [1.]\n",
      " [6.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [8.]\n",
      " [6.]\n",
      " [9.]\n",
      " [1.]\n",
      " [6.]\n",
      " [8.]\n",
      " [6.]\n",
      " [9.]\n",
      " [6.]\n",
      " [7.]\n",
      " [4.]\n",
      " [4.]\n",
      " [8.]\n",
      " [8.]\n",
      " [3.]\n",
      " [1.]\n",
      " [8.]\n",
      " [4.]\n",
      " [6.]\n",
      " [7.]\n",
      " [0.]\n",
      " [7.]\n",
      " [9.]\n",
      " [4.]\n",
      " [1.]\n",
      " [8.]\n",
      " [4.]\n",
      " [8.]\n",
      " [1.]\n",
      " [0.]\n",
      " [8.]\n",
      " [1.]\n",
      " [8.]\n",
      " [6.]\n",
      " [0.]\n",
      " [1.]\n",
      " [7.]\n",
      " [4.]\n",
      " [0.]\n",
      " [5.]\n",
      " [1.]\n",
      " [3.]\n",
      " [6.]\n",
      " [8.]\n",
      " [0.]\n",
      " [4.]\n",
      " [8.]\n",
      " [4.]\n",
      " [5.]\n",
      " [0.]\n",
      " [9.]\n",
      " [9.]\n",
      " [3.]\n",
      " [7.]\n",
      " [8.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [9.]\n",
      " [9.]\n",
      " [1.]\n",
      " [0.]\n",
      " [5.]\n",
      " [7.]\n",
      " [8.]\n",
      " [7.]\n",
      " [8.]\n",
      " [7.]\n",
      " [5.]\n",
      " [7.]\n",
      " [5.]\n",
      " [0.]\n",
      " [7.]\n",
      " [3.]\n",
      " [3.]\n",
      " [5.]\n",
      " [8.]\n",
      " [9.]\n",
      " [1.]\n",
      " [9.]\n",
      " [9.]\n",
      " [2.]\n",
      " [6.]\n",
      " [2.]\n",
      " [9.]\n",
      " [7.]\n",
      " [7.]\n",
      " [9.]\n",
      " [2.]\n",
      " [8.]\n",
      " [5.]\n",
      " [3.]\n",
      " [6.]\n",
      " [8.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [7.]\n",
      " [9.]\n",
      " [8.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [9.]\n",
      " [9.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [6.]\n",
      " [6.]\n",
      " [3.]\n",
      " [7.]\n",
      " [8.]\n",
      " [6.]\n",
      " [3.]\n",
      " [7.]\n",
      " [1.]\n",
      " [7.]\n",
      " [5.]\n",
      " [6.]\n",
      " [4.]]\n"
     ]
    }
   ],
   "source": [
    "y_predict= classification.predict(X_val)\n",
    "print(\"predicted labels is \\n\",y_predict)\n",
    "print(\"truth table\\n\",Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ff23491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_val, y_predict) # calculate the accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d4e8653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8138888888888889"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict= classification.predict(X_test)\n",
    "accuracy_score(Y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ba9a09",
   "metadata": {},
   "source": [
    "# k-NN model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeaf73c",
   "metadata": {},
   "source": [
    "the accuracy of the model cannot reach to 95% whatever the number of neighbours is, may be it is not the right model \n",
    "The number of n_neighbors referes to hyperprameters because it achieve high accuracy which possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6878d2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.973665961010276"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math \n",
    "math.sqrt(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "62e34005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classification2 =KNeighborsClassifier(n_neighbors=12,p=2,metric='euclidear') #choosing the number of neighbors and number of class we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "07c5c40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  0  0  0  0  1  0  0  1  0]\n",
      " [ 0 27  2  2  6  0  0  0  1  0]\n",
      " [ 0  0 25  0  2  0  2  0  0  0]\n",
      " [ 0  2  2 31  0  1  0  1  1  0]\n",
      " [ 3  2  0  0 31  0  0  2  1  0]\n",
      " [ 0  0  1  1  0 38  2  1  0  1]\n",
      " [ 0  0  0  0  3  0 31  0  0  0]\n",
      " [ 0  1  0  0  1  1  0 33  0  1]\n",
      " [ 0  0  3  3  3  2  2  0 25  1]\n",
      " [ 0  3  0  1  0  1  0  2  1 22]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test,y_predict) #we must comput the confusion matrix so we can calculate the accuracy \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d125ff28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8144390335814583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(Y_test,y_predict,average='macro')) #knowing the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29700fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8138888888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test,y_predict)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a9532a",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fd0b64",
   "metadata": {},
   "source": [
    "using this model made the accuracy reach to 96% which is more than required \n",
    "May be it is the best model as it achieved the highest accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "33358eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import math\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1ed8eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr=LogisticRegression()\n",
    "logisticRegr.fit(X_train,Y_train) # fitting between the Y_train and X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a9bd849f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.]\n"
     ]
    }
   ],
   "source": [
    "print(logisticRegr.predict(X_test[0].reshape(1,-1)))\n",
    "predictions=logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52926b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  0  1  0  0  0  0  0  0  0]\n",
      " [ 0 36  0  0  2  0  0  0  0  0]\n",
      " [ 0  1 28  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 38  0  0  0  0  0  0]\n",
      " [ 0  1  0  0 38  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 42  1  1  0  0]\n",
      " [ 0  1  0  0  0  0 32  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 37  0  0]\n",
      " [ 1  1  1  0  0  0  0  0 36  0]\n",
      " [ 0  0  0  0  0  1  0  0  0 29]]\n"
     ]
    }
   ],
   "source": [
    "cm1= metrics.confusion_matrix(Y_test,predictions) \n",
    "print(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2289155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9638888888888889\n"
     ]
    }
   ],
   "source": [
    "score=logisticRegr.score(X_test,Y_test) #calculating the score to know the accuracy of the model\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "970a2a4939579a4c22872227820a264ec023ee5692739211cbaca24386397975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
